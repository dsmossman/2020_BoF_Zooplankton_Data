rm(temp)
for(k in 1:nrow(data4)) {
data3$Shelf_Type[k] = NOAA_NJ_LI_Strata$Shelf_Type[as.numeric(data3$Shelf_Type[k])]
}
View(data3)
data3 %>%
group_by(Species, Shelf_Type) %>%
reframe(Concentration = mean(Abundance))
temp = st_intersects(data3$geometry, NOAA_NJ_LI_Strata$geometry)
temp[lengths(temp) == 0] = NA
data3$Shelf_Type = temp %>% unlist()
rm(temp)
View(data3)
for(k in 1:nrow(data3)) {
data3$Shelf_Type[k] = NOAA_NJ_LI_Strata$Shelf_Type[as.numeric(data3$Shelf_Type[k])]
}
data3 %>%
group_by(Species, Shelf_Type) %>%
reframe(Concentration = mean(Abundance))
View(ECOMON_data)
View(ECOMON_data_mean)
temp = st_intersects(ECOMON_data_expanded$geometry, NOAA_NJ_LI_Strata$geometry)
temp[lengths(temp) == 0] = NA
ECOMON_data_expanded$Shelf_Type = temp %>% unlist()
rm(temp)
temp = st_intersects(ECOMON_data_expanded$geometry, NOAA_NJ_LI_Strata$geometry)
temp[lengths(temp) == 0] = NA
ECOMON_data_expanded$Shelf_Type = temp %>% unlist()
rm(temp)
for(k in 1:nrow(ECOMON_data_expanded)) {
ECOMON_data_expanded$Shelf_Type[k] = NOAA_NJ_LI_Strata$Shelf_Type[as.numeric(ECOMON_data_expanded$Shelf_Type[k])]
}
ECOMON_data_expanded %>%
filter(Season == "Spring") %>% # currently needs to be changed on a per-deployment basis
mutate(Species = case_when(
Species == "Calanus finmarchicus" ~ "Large Copepod",
Species != "Calanus finmarchicus" ~ "Small Copepod"
)) %>%
st_drop_geometry() %>%
group_by(Species) %>%
reframe(Concentration = mean(Concentrations))
#####
rm(list = ls())
setwd("C:/Users/dmossman/Box/2022 MSc Thesis Work/")
## Libraries
library(tidyverse)
library(oce)
library(ocedata)
library(R.utils)
library(readxl)
library(rstatix)
library(emmeans)
library(modelr)
library(ggpubr)
library(pracma)
library(lmodel2)
## Project Structure
sourceDirectory('Code/Hansen Zooplankton Code and Sample Data/src',
modifiedOnly = F)
load(paste0(processed_dir, "Net_Data_With_Sv.rda"))
## Project Structure
sourceDirectory('Code/Hansen Zooplankton Code and Sample Data/src',
modifiedOnly = F)
function_dir = 'Code/Hansen Zooplankton Code and Sample Data/src/'
processed_dir = 'Processed_Data/'
data_dir = 'Raw_Data/'
figure_dir = 'Visuals/'
report_dir = getwd()
load(paste0(processed_dir, "Net_Data_With_Sv.rda"))
setwd("C:/Users/Delphine/Box/2022 MSc Thesis Work/")
## Project Structure
sourceDirectory('Code/Hansen Zooplankton Code and Sample Data/src',
modifiedOnly = F)
function_dir = 'Code/Hansen Zooplankton Code and Sample Data/src/'
processed_dir = 'Processed_Data/'
data_dir = 'Raw_Data/'
figure_dir = 'Visuals/'
report_dir = getwd()
load(paste0(processed_dir, "Net_Data_With_Sv.rda"))
echo_filenames = list.files(paste0(processed_dir, 'Glider'), pattern="^Integrated_Sv_[0-9]{2}_", full.names=TRUE)
echo_ldf = lapply(echo_filenames, function(x) read.table(x, header = TRUE, row.names = 1))
echo_masked_filenames = list.files(paste0(processed_dir, 'Glider'), pattern="^Integrated_Sv_Masked_[0-9]{2}", full.names=TRUE)
echo_masked_ldf = lapply(echo_masked_filenames, function(x) read.table(x, header = TRUE, row.names = 1))
# Full multinet Sv/Sv diff models
multi_filenames = list.files(paste0(processed_dir, 'Multinet'), pattern="^Modeled_Sv_[0-9]", full.names=TRUE)
multi_ldf = lapply(multi_filenames, read.table)
remove_outliers = function(x,var) {
qnt = quantile(unlist(x[var]), probs=c(.25, .75), na.rm = T)
H = 1.5 * IQR(unlist(x[var]), na.rm = T)
x = x %>% filter(!(x[var] <= (qnt[1] - H) | x[var] >= (qnt[2] + H)))
return(x)
}
temp1 = c()
temp2 = c()
for(j in 1:4) { # for each frequency
for (i in 1:length(multi_ldf)) { # for each multinet tow
temp1 = rbind(temp1, t(multi_ldf[[i]][j, ])) # frequency change line
temp2 = rbind(temp2, t(echo_ldf[[i]][j, ])) # frequency change line
}
}
basin_list = rbind(t(t(rep("OB", times = 25))), t(t(rep("GMB", times = 40))), t(t(rep("OB", times = 15))))
correlation_sv = data.frame(
rep(basin_list, times = 4),
rep(rep(levels(Net_Data$station), each = 5), times = 4),
rep(c("130kHz", "200kHz", "455kHz", "769kHz"), each = length(multi_ldf) * 5),
rep(colnames(multi_ldf[[1]]), times = length(multi_ldf) * 4),
NA,
10 * log10(temp1),
10 * log10(temp2)
)
#rm(temp1, temp2)
colnames(correlation_sv) = c("Basin", "Station", "Frequency", "Net", "Community_Comp", "Multi_Sv", "Echo_Sv")
#correlation_sv$Frequency = as.factor(correlation_sv$Frequency)
for(i in 1:nrow(correlation_sv)) {
stn = correlation_sv$Station[i]
netnum = substr(correlation_sv$Net[i],4,4)
correlation_sv$Community_Comp[i] = Net_Data$community_comp[which(Net_Data$station == stn & Net_Data$net == netnum)][1]
}
temp3 = c()
temp4 = c()
for(j in 1:4) {
for (i in 1:length(multi_ldf)) {
temp3 = rbind(temp3, t(multi_ldf[[i]][j, ])) # frequency change line
if(j != 1) {
temp4 = rbind(temp4, t(echo_masked_ldf[[i]][j - 1, ])) # frequency change line
}
}
}
temp4 = as.matrix(c(temp2[1:80], temp4))
correlation_masked_sv = data.frame(
rep(basin_list, times = 4),
rep(rep(levels(Net_Data$station), each = 5), times = 4),
rep(
c("130kHz", "200kHz", "455kHz", "769kHz"),
each = length(multi_ldf) * 5
),
rep(colnames(multi_ldf[[1]]), times = length(multi_ldf) * 4),
NA,
10 * log10(temp3),
10 * log10(temp4)
)
#rm(temp1, temp2)
colnames(correlation_masked_sv) = c("Basin", "Station", "Frequency", "Net", "Community_Comp", "Multi_Sv", "Echo_Masked_Sv")
correlation_masked_sv[correlation_masked_sv$Echo_Masked_Sv == -Inf,7] = NA
for(i in 1:nrow(correlation_masked_sv)) {
stn = correlation_masked_sv$Station[i]
netnum = substr(correlation_masked_sv$Net[i],4,4)
correlation_masked_sv$Community_Comp[i] = Net_Data$community_comp[which(Net_Data$station == stn & Net_Data$net == netnum)][1]
}
correlation_masked_sv = correlation_masked_sv %>%
group_by(Frequency) %>%
#do(remove_outliers(.,"Echo_Masked_Sv")) %>%
do(remove_outliers(.,"Echo_Masked_Sv"))
copepod_filenames = list.files(paste0(processed_dir, 'Multinet/Copepods'), pattern="^Modeled", full.names=TRUE)
copepod_ldf = lapply(copepod_filenames, read.table)
# Correlation
temp5 = c()
temp6 = c()
# frequencies: 1 = 130 kHz, 2 = 200 kHz, 3 = 455 kHz, 4 = 769 kHz
# frequency differences: 1 = 200 - 130 kHz, 2 = 455 - 200 kHz, 3 = 769 - 455 kHz
for(j in 1:4) {
for (i in 1:length(copepod_ldf)) {
temp5 = rbind(temp5, t(copepod_ldf[[i]][j, ])) # frequency change line
if(j != 1) {
temp6 = rbind(temp6, t(echo_masked_ldf[[i]][j - 1, ])) # frequency change line
}
}
}
temp6 = as.matrix(c(temp2[1:80], temp6))
correlation_copepod = data.frame(rep(basin_list, times = 4),
rep(rep(levels(Net_Data$station), each = 5), times = 4),
rep(c("130kHz", "200kHz","455kHz","769kHz"), each = length(copepod_ldf) * 5),
rep(colnames(copepod_ldf[[1]]), times = length(copepod_ldf) * 4),
NA,
10 * log10(temp5),
10 * log10(temp6),
10 * log10(temp2))
# rm(temp1, temp2, temp3)"
colnames(correlation_copepod) = c("Basin", "Station", "Frequency", "Net", "Community_Comp", "Copepod_Sv", "Echo_Masked_Sv", "Echo_Sv")
correlation_copepod[correlation_copepod$Echo_Masked_Sv == -Inf,7] = NA
for(i in 1:nrow(correlation_copepod)) {
stn = correlation_copepod$Station[i]
netnum = substr(correlation_copepod$Net[i],4,4)
correlation_copepod$Community_Comp[i] = Net_Data$community_comp[which(Net_Data$station == stn & Net_Data$net == netnum)][1]
}
correlation_copepod = correlation_copepod %>%
group_by(Frequency) %>%
#  do(remove_outliers(.,"Echo_Masked_Sv")) %>%
do(remove_outliers(.,"Echo_Masked_Sv"))
cfin_filenames = list.files(paste0(processed_dir, 'Multinet/CFin'), pattern="^Modeled", full.names=TRUE)
cfin_ldf = lapply(cfin_filenames, read.table)
# Correlation
temp9 = c()
temp10 = c()
# frequencies: 1 = 130 kHz, 2 = 200 kHz, 3 = 455 kHz, 4 = 769 kHz
# frequency differences: 1 = 200 - 130 kHz, 2 = 455 - 200 kHz, 3 = 769 - 455 kHz
for(j in 1:4) {
for (i in 1:length(cfin_ldf)) {
temp9 = rbind(temp9, t(cfin_ldf[[i]][j, ])) # frequency change line
if(j != 1) {
temp10 = rbind(temp10, t(echo_masked_ldf[[i]][j - 1, ])) # frequency change line
}
}
}
temp10 = as.matrix(c(temp2[1:80], temp10))
correlation_cfin = data.frame(rep(basin_list, times = 4),
rep(rep(levels(Net_Data$station), each = 5), times = 4),
rep(c("130kHz","200kHz","455kHz","769kHz"), each = length(cfin_ldf) * 5),
rep(colnames(cfin_ldf[[1]]), times = length(cfin_ldf) * 4),
NA,
10 * log10(temp9),
10 * log10(temp10))
# rm(temp1, temp2, temp3)
colnames(correlation_cfin) = c("Basin", "Station", "Frequency", "Net", "Community_Comp", "Cfin_Sv", "Echo_Masked_Sv")
correlation_cfin[correlation_cfin$Echo_Masked_Sv == -Inf,7] = NA
for(i in 1:nrow(correlation_cfin)) {
stn = correlation_cfin$Station[i]
netnum = substr(correlation_cfin$Net[i],4,4)
correlation_cfin$Community_Comp[i] = Net_Data$community_comp[which(Net_Data$station == stn & Net_Data$net == netnum)][1]
}
correlation_cfin = correlation_cfin %>%
group_by(Frequency) %>%
#  do(remove_outliers(.,"Echo_Masked_Sv")) %>%
do(remove_outliers(.,"Echo_Masked_Sv"))
result = manova(cbind(Cfin_Sv, Echo_Masked_Sv) ~ Frequency * Community_Comp,
data = correlation_cfin)
summary(result)
(summary.aov(result)[[" Response Cfin_Sv"]])
(summary.aov(result)[[" Response Echo_Masked_Sv"]])
models = correlation_cfin %>%
group_by(Frequency, Basin) %>%
#filter(Echo_Masked_Sv > median(Echo_Masked_Sv)) %>%
do(model = summary(lm(Cfin_Sv ~ Echo_Masked_Sv, data = .)))
for(i in 1:length(models$model)){
cat(paste0(models[[1]][i], ": "))
cat("\n")
print(signif(models$model[[i]][["coefficients"]], digits = 2))
cat(paste0("R-squared: ", signif(models$model[[i]][["r.squared"]], digits = 2)))
cat("\n")
cat(paste0("p-value: ", signif(pf(models$model[[i]][["fstatistic"]][["value"]],
models$model[[i]][["fstatistic"]][["numdf"]],
models$model[[i]][["fstatistic"]][["dendf"]],
lower.tail = FALSE), digits = 2)))
cat("\n\n")
}
View(models)
models = correlation_cfin %>%
group_by(Frequency) %>%
#filter(Echo_Masked_Sv > median(Echo_Masked_Sv)) %>%
do(model = summary(lm(Cfin_Sv ~ Echo_Masked_Sv, data = .)))
for(i in 1:length(models$model)){
cat(paste0(models[[1]][i], ": "))
cat("\n")
print(signif(models$model[[i]][["coefficients"]], digits = 2))
cat(paste0("R-squared: ", signif(models$model[[i]][["r.squared"]], digits = 2)))
cat("\n")
cat(paste0("p-value: ", signif(pf(models$model[[i]][["fstatistic"]][["value"]],
models$model[[i]][["fstatistic"]][["numdf"]],
models$model[[i]][["fstatistic"]][["dendf"]],
lower.tail = FALSE), digits = 2)))
cat("\n\n")
}
models = correlation_cfin %>%
ungroup() %>%
group_by(Frequency) %>%
#filter(Echo_Masked_Sv > median(Echo_Masked_Sv)) %>%
do(model = (lm(Cfin_Sv ~ Echo_Masked_Sv, data = .))) %>%
ungroup()
for(i in 1:length(models$model)) {
x = residuals(models$model[[i]])
cat(paste0(models[[1]][i], " RMSE: ", round(sqrt(mean(x^2,na.rm=T)), digits = 2)))
cat("\n")
}
plot(fitted(models[[2]][[1]]),resid(models[[2]][[1]]))
abline(0,0)
plot(fitted(models[[2]][[2]]),resid(models[[2]][[2]]))
abline(0,0)
plot(fitted(models[[2]][[3]]),resid(models[[2]][[3]]))
abline(0,0)
plot(fitted(models[[2]][[4]]),resid(models[[2]][[4]]))
abline(0,0)
test = data.frame(Echo_Masked_Sv = correlation_cfin$Echo_Masked_Sv[correlation_cfin$Frequency == "455kHz"],
Cfin_Sv = correlation_cfin$Cfin_Sv[correlation_cfin$Frequency == "455kHz"])
test = test[!is.na(test$Cfin_Sv),]
intercept = mean(test$Cfin_Sv - test$Echo_Masked_Sv) # lm intercept when slope = 1
test$Predicted = 1 * test$Echo_Masked_Sv + intercept
test$Residuals = test$Cfin_Sv - test$Predicted
intercept
test$Predicted = 1 * test$Echo_Masked_Sv + intercept
test$Residuals = test$Cfin_Sv - test$Predicted
test_mean = mean(test$Cfin_Sv,na.rm=T)
test_SS_res = sum((test$Residuals^2),na.rm=T)
# test_SS_tot = sum(((test$Cfin_Sv - test_mean)^2),na.rm=T)
test_SS_reg = sum(((test$Predicted - test_mean)^2),na.rm=T)
#
# 1 - test_SS_res/test_SS_tot
cor(test$Predicted, test$Cfin_Sv)^2 #r^2 for slope=1 model
test_f = test_SS_reg/(test_SS_res/(nrow(test)-1-1))
pf(test_f,
1,
nrow(test)-1-1,
lower.tail = FALSE) # p-value for slope=1 model
sqrt(mean(test$Residuals^2, na.rm = TRUE)) # RMSE for slope=1 model
models = correlation_cfin %>%
ungroup() %>%
group_by(Frequency) %>%
#filter(Echo_Masked_Sv > median(Echo_Masked_Sv)) %>%
do(model = (lm(Cfin_Sv ~ Echo_Masked_Sv, data = .))) %>%
ungroup()
for(i in 1:length(models$model)) {
x = residuals(models$model[[i]])
cat(paste0(models[[1]][i], " RMSE: ", round(sqrt(mean(x^2,na.rm=T)), digits = 2)))
cat("\n")
}
models = correlation_cfin %>%
group_by(Frequency) %>%
#filter(Echo_Masked_Sv > median(Echo_Masked_Sv)) %>%
do(model = summary(lm(Cfin_Sv ~ Echo_Masked_Sv, data = .)))
for(i in 1:length(models$model)){
cat(paste0(models[[1]][i], ": "))
cat("\n")
print(signif(models$model[[i]][["coefficients"]], digits = 2))
cat(paste0("R-squared: ", signif(models$model[[i]][["r.squared"]], digits = 2)))
cat("\n")
cat(paste0("p-value: ", signif(pf(models$model[[i]][["fstatistic"]][["value"]],
models$model[[i]][["fstatistic"]][["numdf"]],
models$model[[i]][["fstatistic"]][["dendf"]],
lower.tail = FALSE), digits = 2)))
cat("\n\n")
}
rm(list = ls())
library(tidyverse)
library(readxl)
library(sf)
library(R.utils)
library(tcltk)
sourceDirectory(
"H:/dm1679/Code/R_Functions",
modifiedOnly = F
)
figure_dir = "C:/Users/Delphine/Box/Zooplankton Protocols and Data/Figures/"
load("C:/Users/Delphine/Box/Zooplankton Protocols and Data/RMI Datasheets/zooplankton_tows_RMI.rda")
## Plotting
load("C:/Users/Delphine/Box/Zooplankton Protocols and Data/NOAA ecomon Zooplankton data 1977_2021/ECOMON_R_Data.rda")
glider_dep = choose_directory() %>% substring(., regexpr("ru[0-9]{2}-*", .))
year = substr(glider_dep,6,9)
data_dir = paste0("C:/Users/Delphine/Box/Glider Data/",
glider_dep,
"/Derived Biomass Data/")
load(paste0(data_dir, "Processed_Abundance_Biomass_Data.rda"))
View(data3)
View(data)
View(data)
data %>%
mutate(Concentration = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
))
data %>%
mutate(Concentration = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
)) %>%
filter(Species == "Large Copepod") %>%
select(Concentration)
data %>%
mutate(Concentration = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
)) %>%
filter(Species == "Large Copepod") %>%
group_by(Echo_Num, Species) %>%
reframe(
Abundance = sum(Abundance),
Biomass = sum(Biomass),
NASC = mean(NASC),
Ping = mean(c(Ping_S, Ping_E)),
Depth = mean(Depth_mean, na.rm = T),
Date = mean(c(Time_M)),
Lat = mean(c(Lat_M)),
Long = mean(c(Lon_M)),
Seafloor_Depth = mean(c(Exclude_below_line_depth_mean + 1),
na.rm = T)
)
data %>%
mutate(Concentration = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
)) %>%
group_by(Echo_Num, Species) %>%
reframe(
Abundance = sum(Abundance),
Biomass = sum(Biomass),
NASC = mean(NASC),
Ping = mean(c(Ping_S, Ping_E)),
Depth = mean(Depth_mean, na.rm = T),
Date = mean(c(Time_M)),
Lat = mean(c(Lat_M)),
Long = mean(c(Lon_M)),
Seafloor_Depth = mean(c(Exclude_below_line_depth_mean + 1),
na.rm = T)
)
data %>%
mutate(Concentration = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
)) %>%
group_by(Echo_Num, Species) %>%
reframe(
Abundance = sum(Abundance),
Biomass = sum(Biomass),
NASC = mean(NASC),
Ping = mean(c(Ping_S, Ping_E)),
Depth = mean(Depth_mean, na.rm = T),
Date = mean(c(Time_M)),
Lat = mean(c(Lat_M)),
Long = mean(c(Lon_M)),
Seafloor_Depth = mean(c(Exclude_below_line_depth_mean + 1),
na.rm = T)
) %>%
ungroup() %>%
group_by(Species) %>%
reframe(Concentration = mean(Abundance))
data3 %>%
group_by(Species) %>%
reframe(Concentration = mean(Abundance))
View(data)
data %>%
mutate(Abundance = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
)) %>%
group_by(Echo_Num, Species) %>%
reframe(
Abundance = sum(Abundance),
Biomass = sum(Biomass),
NASC = mean(NASC),
Ping = mean(c(Ping_S, Ping_E)),
Depth = mean(Depth_mean, na.rm = T),
Date = mean(c(Time_M)),
Lat = mean(c(Lat_M)),
Long = mean(c(Lon_M)),
Seafloor_Depth = mean(c(Exclude_below_line_depth_mean + 1),
na.rm = T)
) %>%
ungroup() %>%
group_by(Species) %>%
reframe(Concentration = mean(Abundance))
data %>%
mutate(Abundance = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
)) %>%
group_by(Echo_Num, Species) %>%
reframe(
Abundance = sum(Abundance),
Biomass = sum(Biomass),
NASC = mean(NASC),
Ping = mean(c(Ping_S, Ping_E)),
Depth = mean(Depth_mean, na.rm = T),
Date = mean(c(Time_M)),
Lat = mean(c(Lat_M)),
Long = mean(c(Lon_M)),
Seafloor_Depth = mean(c(Exclude_below_line_depth_mean + 1),
na.rm = T)
) %>%
ungroup() %>%
group_by(Species)
data %>%
mutate(Abundance = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
))
View(data %>%
mutate(Abundance = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10)
)))
data %>%
mutate(Abundance = case_when(
(Frequency == 455 & Species == "Large Copepod") ~
10^(((-54 + Sv_mean * 0.44) - -108.3)/10), .default = Abundance
)) %>%
group_by(Echo_Num, Species) %>%
reframe(
Abundance = sum(Abundance),
Biomass = sum(Biomass),
NASC = mean(NASC),
Ping = mean(c(Ping_S, Ping_E)),
Depth = mean(Depth_mean, na.rm = T),
Date = mean(c(Time_M)),
Lat = mean(c(Lat_M)),
Long = mean(c(Lon_M)),
Seafloor_Depth = mean(c(Exclude_below_line_depth_mean + 1),
na.rm = T)
) %>%
ungroup() %>%
group_by(Species) %>%
reframe(Concentration = mean(Abundance))
net_data_full %>%
filter(glider_trajectory == glider_dep & taxa_group %in% c("Copepod (small)", "Copepod (large)")) %>%
group_by(taxa_group) %>%
reframe(Concentration = mean(concentration))
ECOMON_data_expanded %>%
filter(Season == "Spring") %>% # currently needs to be changed on a per-deployment basis
mutate(Species = case_when(
Species == "Calanus finmarchicus" ~ "Large Copepod",
Species != "Calanus finmarchicus" ~ "Small Copepod"
)) %>%
st_drop_geometry() %>%
group_by(Species) %>%
reframe(Concentration = mean(Concentrations))
